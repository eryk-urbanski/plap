{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4512,\n",
       " 'C:/Users/windo/Desktop/Inżynierka/plap/thesis/audios/nEMO\\\\samples\\\\EB0_anger_27.wav')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dir_name = 'C:/Users/windo/Desktop/Inżynierka/plap/thesis/audios/nEMO'\n",
    "# dir_name = 'C:/Users/windo/Documents/ravdess-dataset/audio_speech_actors_01-24'\n",
    "\n",
    "# Initialize a list to hold the file names\n",
    "all_files = []\n",
    "\n",
    "# Traverse all subfolders and files using os.walk()\n",
    "for root, _, file_names in os.walk(dir_name):\n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(root, file_name)\n",
    "        if os.path.isfile(file_path):  # Check if it's a file\n",
    "            all_files.append(file_path)\n",
    "\n",
    "all_files = sorted(all_files)\n",
    "\n",
    "# # Display the collected file names\n",
    "# print('List of all files in the folders:')\n",
    "# for file in all_files:\n",
    "#     print(file)\n",
    "\n",
    "# Emotions in the RAVDESS dataset\n",
    "emotions = {\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "\n",
    "# desired csv columns:\n",
    "# label/name(actor number, take, etc) emotion(class) feature1 feature2...\n",
    "# or class at the end?\n",
    "len(all_files), all_files[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsample the database to 'neutral', 'happy' and 'sad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wanted_classes = {'01', '03', '04'}\n",
    "\n",
    "filtered_files = [filepath for filepath in all_files if filepath.split('\\\\')[-1].split('-')[2] in wanted_classes]\n",
    "\n",
    "len(filtered_files)\n",
    "\n",
    "# Print the filtered filepaths\n",
    "# for file in filtered_files:\n",
    "#     print(file)\n",
    "# VISUALIZATION\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure(figsize=(35,4))\n",
    "plt.subplot(1,3,1)\n",
    "emotion_list, count = np.unique([filepath.split('\\\\')[-1].split('-')[2] for filepath in filtered_files], return_counts=True)\n",
    "emotion_list, count\n",
    "emotions_pl = {\n",
    "  '01':'neutralność',\n",
    "  '02':'spokój',\n",
    "  '03':'szczęście',\n",
    "  '04':'smutek',\n",
    "  '05':'złość',\n",
    "  '06':'strach',\n",
    "  '07':'obrzydzenie',\n",
    "  '08':'zaskoczenie'\n",
    "}\n",
    "plt.bar(x=range(3), height=count)\n",
    "plt.xticks(ticks=range(3), labels = [emotions_pl[emotion] for emotion in emotion_list], fontsize=10)\n",
    "plt.xlabel('Klasa')\n",
    "plt.tick_params(labelsize=16)\n",
    "plt.ylabel('Liczba próbek (obserwacji)')\n",
    "# Add text annotations\n",
    "for i, value in enumerate(count):\n",
    "    plt.text(i, value + 1, str(value), ha='center', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_files = [filepath for filepath in all_files if '.wav' in filepath and 'neutral' in filepath or 'happiness' in filepath or 'sadness' in filepath]\n",
    "# # Downsample nEMO\n",
    "# len(filtered_files)\n",
    "# # wanted_classes = {'neutral', 'happiness', 'sadness'}\n",
    "# # filtered_files = [filepath for filepath in all_files if filepath.split('\\\\')[-1].split('_')[1] in wanted_classes]\n",
    "\n",
    "# # # Print the filtered filepaths\n",
    "# # for file in filtered_files:\n",
    "# #     print(file)\n",
    "# # filtered_files = filtered_files[0:-1:5]\n",
    "# len(filtered_files)\n",
    "\n",
    "# VISUALIZATION\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# plt.figure(figsize=(35,4))\n",
    "# plt.subplot(1,3,1)\n",
    "# temp = [filepath.split('\\\\')[-1].split('_')[1] for filepath in all_files if '.wav' in filepath]\n",
    "# emotion_list, count = np.unique(temp, return_counts=True)\n",
    "# emotion_list, count\n",
    "# emotions_pl = {\n",
    "#   'neutral':'neutralność',\n",
    "#   'happiness':'szczęście',\n",
    "#   'sadness':'smutek',\n",
    "#   'anger':'złość',\n",
    "#   'fear':'strach',\n",
    "#   'surprised':'zaskoczenie'\n",
    "# }\n",
    "# #(anger, fear, happiness, sadness, surprised, and neutral)\n",
    "# plt.bar(x=range(6), height=count)\n",
    "# plt.xticks(ticks=range(6), labels = [emotions_pl[emotion] for emotion in emotion_list], fontsize=10)\n",
    "# plt.xlabel('Klasa')\n",
    "# plt.tick_params(labelsize=16)\n",
    "# plt.ylabel('Liczba próbek (obserwacji)')\n",
    "# # Add text annotations\n",
    "# for i, value in enumerate(count):\n",
    "#     plt.text(i, value + 1, str(value), ha='center', fontsize=10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import plap\n",
    "\n",
    "# Use plap for parameterization\n",
    "# Newest with ASB, ASP and variance across ASF\n",
    "fvector = plap.FeatureVector(\"asc\",\"asc_var\",\"ass\",\"ass_var\",\"asf\",\"asf_mean\",\"asf_var\",\"asf_var_mean\",\"aff\",\"aff_var\",\"lat\",\"tc\",\"sc\",\"sc_var\",\"hsc\",\"hsd\",\"hss\",\"hsv\",\"asb\",\"asb_mean\",\"asp\",\"asp_mean\",\"mfcc\")\n",
    "# fvector = plap.FeatureVector(\"asc\",\"asc_var\",\"ass\",\"ass_var\",\"asf\",\"asf_mean\",\"aff\",\"aff_var\",\"lat\",\"tc\",\"sc\",\"sc_var\",\"hsc\",\"hsd\",\"hss\",\"hsv\")\n",
    "# fvector = plap.FeatureVector(\"asc\",\"ass\",\"asf\",\"lat\",\"tc\",\"sc\",\"hsc\",\"hsd\",\"hss\",\"hsv\")\n",
    "# block_size_ms = block_size_samples/sr*1000 = 1024/48000*1000 ~= 21.34 ms\n",
    "preprocessor = plap.Preprocessor(preemphasis_coeff=None, block_size=1024, window_type=\"hamming\")\n",
    "\n",
    "def extract_features(audio_path):\n",
    "    plap.parameterize(audio_path=audio_path, fvector=fvector, preprocessor=preprocessor)\n",
    "    return fvector.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Define the CSV filename\n",
    "# fvector = plap.FeatureVector(\"asc\",\"ass\",\"asf\",\"lat\",\"tc\",\"sc\",\"hsc\",\"hsd\",\"hss\",\"hsv\")\n",
    "csv_filename = './python_csv/nEMO_wholedataset.csv'\n",
    "\n",
    "# Feature names compatibility taking into account vector features\n",
    "feature_names_compat = [feature.upper() for feature in fvector.features]\n",
    "\n",
    "# Define mapping for base features and their corresponding counts\n",
    "feature_mapping = {\n",
    "    'ASF': 24,\n",
    "    'ASF_VAR': 24,\n",
    "    'ASB': 20,\n",
    "    'ASP': 21,\n",
    "    'MFCC': 20\n",
    "}\n",
    "\n",
    "i = 0\n",
    "while i < len(feature_names_compat):\n",
    "    base_feature = feature_names_compat[i]\n",
    "    \n",
    "    if base_feature in feature_mapping:\n",
    "        count = feature_mapping[base_feature]\n",
    "        feature_names_compat[i] = f'{base_feature}1'  # Set the first feature name\n",
    "        \n",
    "        # Create the numbered features list\n",
    "        numbered_features = [f'{base_feature}{k}' for k in range(2, count + 1)]\n",
    "        \n",
    "        # Insert numbered features right after the base feature\n",
    "        feature_names_compat[i+1:i+1] = numbered_features\n",
    "        \n",
    "        # Skip over the newly inserted features\n",
    "        i += len(numbered_features)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "feature_names_compat\n",
    "# Initialize the CSV file with headers\n",
    "headers = ['label', 'class'] + [f'{feature.upper()}' for feature in feature_names_compat]\n",
    "with open(csv_filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Iterate over each audio file\n",
    "initial_i = 2327\n",
    "# end_i = 150\n",
    "i = initial_i\n",
    "processed = 2327\n",
    "for filename in filtered_files[initial_i:]:\n",
    "    if filename.endswith('.wav'):  # Ensure only audio files are processed\n",
    "        \n",
    "        start_time = time.time()\n",
    "        # Extract label and class from the filename (customize this logic as needed)\n",
    "        # audio_filename = filename.split('\\\\')[-1]\n",
    "        # label = audio_filename.removesuffix('.wav')  # Use filename as label\n",
    "        # class_num = audio_filename.split('-')[2]\n",
    "        # class_name = emotions[class_num]\n",
    "        audio_filename = filename.split('\\\\')[-1]\n",
    "        label = audio_filename.removesuffix('.wav')\n",
    "        class_name = audio_filename.split('_')[1]\n",
    "        \n",
    "        print(f'Processing file {audio_filename}')\n",
    "\n",
    "        # Extract 11 features from the audio file\n",
    "        try:\n",
    "            features = extract_features(filename)\n",
    "            processed += 1\n",
    "        except:\n",
    "            print(f'Omitting file{i}')\n",
    "            i += 1\n",
    "            continue\n",
    "        # features = np.zeros(11)\n",
    "\n",
    "        # Prepare the row to be added to the CSV\n",
    "        row = [label, class_name] + list(features)\n",
    "\n",
    "        # Append the new row to the CSV file\n",
    "        with open(csv_filename, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(row)\n",
    "        print(f'Finished file{i} in {time.time() - start_time} s')\n",
    "        i += 1\n",
    "\n",
    "print(\"Feature extraction and CSV writing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
